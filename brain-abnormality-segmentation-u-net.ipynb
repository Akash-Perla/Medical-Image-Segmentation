{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":407317,"sourceType":"datasetVersion","datasetId":181273}],"dockerImageVersionId":30674,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Library setup\n> ##### At this notebook, **Keras and TensorFlow** will be utilized for **model development** and training, leveraging their robust libraries and functionalities.","metadata":{}},{"cell_type":"code","source":"import os\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\nimport warnings\nwarnings.filterwarnings('ignore')\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport plotly.graph_objs as go\nimport tensorflow as tf\nimport keras\nfrom PIL import Image\nfrom sklearn.model_selection import train_test_split\nfrom tqdm.notebook import tqdm\nfrom keras.models import Model\nfrom keras.layers import Input, Conv2D, LeakyReLU, BatchNormalization, MaxPool2D, Conv2DTranspose, concatenate\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\nfrom mlxtend.plotting import plot_confusion_matrix\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Path to the images and masks\nIMAGE_PATH = '/kaggle/input/lgg-mri-segmentation/kaggle_3m'\n\n# Size of the images and masks\nIMAGE_SIZE = (256, 256)\n\n# Number of epochs\nEPOCHS = 60\n\n# Batch size\nBATCH_SIZE = 45","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# A list to hold each image and mask's path\npaths = []\n\nfor dirname in os.listdir(IMAGE_PATH):\n    if os.path.isdir(os.path.join(IMAGE_PATH, dirname)):\n        \n        for filename in os.listdir(os.path.join(IMAGE_PATH, dirname)):\n            # Only the files with ',tif' format should be added to the 'paths' list\n            if filename.endswith('.tif'):\n                paths.append(IMAGE_PATH+'/'+dirname+'/'+filename)\n\nlen(paths), paths[:20:5]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Making dataframes**","metadata":{}},{"cell_type":"code","source":"# Making a dataframe from the list \"paths\" by separating Images and Masks, extracting IDs, and diagnoses.\ndef data_frame(data):\n    # Storing only paths that don't end with 'mask.tiff'\n    images = list(filter(lambda x: not x.endswith('mask.tif'), data))\n    # Sorting images based on the number of each MRI.\n    images.sort(key=lambda x: int(x.rsplit('_', 3)[-1][:-4]))\n    # Sorting by the patient IDs (each patient has more than 1 MRIs)\n    images.sort(key=lambda x: int(x.rsplit('_', 3)[-2]))\n    \n    # Storing the image IDs\n    IDs = list(map(lambda x: x.rsplit('/', 3)[-1][:-4], images))\n\n    # Storing only paths that end with 'mask.tiff'\n    masks = list(filter(lambda x: x.endswith('mask.tif'), data))\n    # Sorting masks based on the number of each MRI.\n    masks.sort(key=lambda x: int(x.rsplit('_', 3)[-2]))\n    # Sorting by the patient IDs (each patient has more than 1 MRIs)\n    masks.sort(key=lambda x: int(x.rsplit('_', 3)[-3]))\n\n    # Opens the images\n    pixels = lambda x: Image.open(x)\n    # Selects the largest pixel\n    largest_pixel = lambda y: np.max(pixels(y))\n    # Determines if the mask contains an abnormality or not (+ or -)\n    # Remember that a negative image's mask is just an entirely black image.\n    diagnotic_function = lambda z: 1 if largest_pixel(z) > 0 else 0\n    # Storing the diagnosis corresponding to each image\n    diagnoses = list(map(lambda x: diagnotic_function(x), masks))\n\n    # Making the dataframe\n    DataFrame = pd.DataFrame({'ID': IDs, 'Image': images, 'Mask': masks, 'Diagnosis': diagnoses})\n    \n    # Dividing the indexes into train, test, and validation\n    train_index, val_index = train_test_split(DataFrame.index.values.tolist(), test_size=0.19, random_state=42)\n    val_index, test_index = train_test_split(val_index, test_size=0.12, random_state=42)\n    \n    # Making train, test, and validation dataframes\n    train_df, val_df, test_df = DataFrame.iloc[train_index], DataFrame.iloc[val_index], DataFrame.iloc[test_index]\n    \n    return train_df, val_df, test_df\n    \n# Making the dataframes\ntrain_df, val_df, test_df = data_frame(paths)\n\nprint(len(train_df), len(val_df), len(test_df))\n\ntrain_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Visualization**","metadata":{}},{"cell_type":"markdown","source":"#### **Positive Images and Masks**","metadata":{}},{"cell_type":"code","source":"def plot_images_and_masks(images, masks, predictions=None, IoU_list=None):\n    num_samples = len(images)\n    # Checking whether the function has been given the prediction array or not\n    num_rows = 2 if type(predictions) == type(None) else 3\n    \n    # Defining figure\n    fig, axes = plt.subplots(num_rows, num_samples,\n                             figsize=(num_samples*5, num_samples+(num_rows*2)), dpi=200)\n    \n    for i in range(num_samples):\n        # Plotting image\n        axes[0, i].imshow(Image.open(images[i]), cmap='gray')\n        axes[0, i].set_title('Image', fontsize=20, fontweight='bold')\n        axes[0, i].axis('off')\n        \n        # Plotting mask\n        axes[1, i].imshow(Image.open(masks[i]), cmap='gray')\n        axes[1, i].set_title('Mask', fontsize=20, fontweight='bold')\n        axes[1, i].axis('off')\n        \n        # Plotting prediction\n        if type(predictions) != type(None):\n            axes[2, i].imshow(predictions[i], cmap='gray')\n            axes[2, i].set_title(f'Prediction | IoU: {round(float(IoU_list[i]), 3)}',\n                                 fontsize=19, fontweight='bold')\n            axes[2, i].axis('off')\n             \n    # Adding title\n    plt.suptitle('Images and Masks', fontsize=30, fontweight='bold')\n    \n    # Showing the figure\n    plt.show()\n\nplot_images_and_masks(train_df[train_df['Diagnosis'] == 1]['Image'].values[:6],\n                      train_df[train_df['Diagnosis'] == 1]['Mask'].values[:6])","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **Negative Images and Masks**","metadata":{}},{"cell_type":"code","source":"plot_images_and_masks(train_df[train_df['Diagnosis'] == 0]['Image'].values[:6],\n                      train_df[train_df['Diagnosis'] == 0]['Mask'].values[:6])","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Class Distribution**","metadata":{}},{"cell_type":"code","source":"def plot_class_distribution(train_df, val_df, test_df):\n    # Counting the class distribution for every dataframe.\n    class_distribution_df1 = train_df['Diagnosis'].value_counts()\n    class_distribution_df2 = val_df['Diagnosis'].value_counts()\n    class_distribution_df3 = test_df['Diagnosis'].value_counts()\n    \n    colors = ['#0504AA', '#ED0101']\n\n    # Defining figure\n    fig = go.Figure()\n\n    # Adding bars for each dataframe and each class\n    for class_label in class_distribution_df1.index:\n        # Getting the name of each class (+ or -)\n        class_name = 'Positive' if class_label == 1 else 'Negative'\n        \n        # Creating stacked bar for each class\n        fig.add_trace(go.Bar(\n            x=['Training', 'Validation', 'Test'],\n            y=[class_distribution_df1.get(class_label, 0),\n               class_distribution_df2.get(class_label, 0),\n               class_distribution_df3.get(class_label, 0)],\n            \n            name=f'{class_name}',\n            marker=dict(color=colors[class_label]),\n            opacity=0.75,\n            width=0.3\n        ))\n    \n    # Updating layout\n    fig.update_layout(\n        height=700,\n        width=800,\n        title_text=\"Class Distribution\",\n        title_font=dict(size=25, family='Balto'),\n        title_x=0.5,\n        title_y=0.98,\n        xaxis=dict(title='Dataframes', title_font=dict(family='Balto', size=19), tickfont=dict(family='Balto', size=19)),\n        yaxis=dict(title='Count', title_font=dict(family='Balto', size=19), tickfont=dict(family='Balto', size=19)),\n        margin=dict(l=60, r=20, t=50, b=40), \n        legend=dict(x=0.78, y=0.98, traceorder='normal', orientation='h', font=dict(family='Balto')),  # Placing legend inside\n        barmode='stack'  # Setting barmode to 'stack' to stack the bars\n                )\n    # Showing the figure\n    fig.show()\n\nplot_class_distribution(train_df, val_df, test_df)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### **Almost 70% of data belong to the negative class**","metadata":{}},{"cell_type":"markdown","source":"# **Data Setup for Model Input**\n> * **At this part**, the **'.tif'** images are **decoded** into NumPy arrays and converted **into tensors** using TensorFlow. Following this, both the images and masks are **resized** ((256, 256, **3**) for images and (256, 256, **1**) for masks). Normalization is applied to the tensor values by dividing them by 255.\n\n\n> * Subsequently, the data is passed to the 'tf.data.Dataset.from_tensor_slices()' function, shuffled, paired (matching images with their corresponding masks), and batched. The batched data is **prefetched** for efficient model input, **overlapping** data pre-processing with model training to **optimize resource utilization** and **enhance training speed**.\n\n\n> * **This process ensures** that the data is **appropriately formatted** and optimized **for input into the model**.","metadata":{}},{"cell_type":"code","source":"# Processes the image\ndef decode_and_resize_image(img_path):\n    # Reading '.tiff' format image\n    img = tf.io.read_file(img_path)\n    with tf.io.gfile.GFile(img_path, 'rb') as f:\n        img = Image.open(f)\n        img = np.array(img)\n    img = tf.convert_to_tensor(img, dtype=tf.float32)\n    img = tf.image.resize(img, IMAGE_SIZE, preserve_aspect_ratio=True)\n    \n    # Normalizing the image to the range [0, 1]\n    img = img / 255.0\n    \n    # Pbar updating, started at the data setup cell.\n    try:\n        pbar.update(1)\n    except:\n        pass\n    \n    return img\n\n# Processes the mask\ndef decode_and_resize_mask(mask_path):\n    # Reading '.tiff' format masks\n    mask = tf.io.read_file(mask_path)\n    with tf.io.gfile.GFile(mask_path, 'rb') as f:\n        mask = Image.open(f)\n        mask = np.array(mask)\n    mask = tf.convert_to_tensor(mask, dtype=tf.float32)\n    mask = np.expand_dims(mask, axis=-1)\n    mask = tf.image.resize(mask, IMAGE_SIZE, method='nearest', preserve_aspect_ratio=True)\n    grayscale_mask = tf.reduce_mean(mask, axis=-1, keepdims=True)\n    \n    # Normalizing the mask to the range [0, 1]\n    grayscale_mask = grayscale_mask / 255.0\n    \n    # Pbar updating, started at the data setup cell.\n    try:\n        pbar.update(1)\n    except:\n        pass\n    \n    return grayscale_mask","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def processed_input(img, mask):\n    # Processed images: (None, 256, 256, 3), Processed masks: (None, 256, 256, 1)\n    return img, mask\n\n# Prepares the dataset\ndef make_dataset(images, masks):\n    dataset = tf.data.Dataset.from_tensor_slices((list(map(lambda x: decode_and_resize_image(x), images)),\n                                                 list(map(lambda x: decode_and_resize_mask(x), masks))))\n    # Shuffle dataset\n    dataset = dataset.shuffle(BATCH_SIZE * 8)\n    # Map dataset\n    dataset = dataset.map(processed_input, num_parallel_calls=tf.data.AUTOTUNE)\n    # While the current batch of data is being processed, prefetching the next batch based on available resources.\n    dataset = dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n\n    return dataset\n\n# Defining Â a Pbar to keep an eye on the procedure.\npbar = tqdm(total=(len(train_df)+len(val_df))*2, position=0, leave=True, colour='green')\n\n# Making the datasets by providing the lists of corresponding masks and images.\ntrain_dataset = make_dataset(list(train_df['Image'].values), list(train_df['Mask'].values))\nvalidation_dataset = make_dataset(list(val_df['Image'].values), list(val_df['Mask'].values))\n\npbar.close()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Now **the datasets are prepared** in the desired format. Images and masks have been processed, paired, and put into batches.","metadata":{}},{"cell_type":"markdown","source":"# **Defining the U-Net Model**\n> **The U-Net model** is defined using a **series of convolutional blocks** for both the encoder and decoder sections.\n> * **The encoder** consists of 4 convolutional blocks, each containing **Conv2D layers** followed by **Batch Normalization, Leaky ReLU activation**, and **Max Pooling 2D** operations.\n\n\n> * **Between the encoder and decoder**, a bridge is established with **Conv2D layers, Batch Normalization**, and **Leaky ReLU** activation to facilitate information flow.\n\n\n> * In **the decoder** section, 4 upsampling blocks are applied, each containing **Conv2DTranspose** layers for upsampling, **concatenation for residual connections**, and the previously mentioned **convolutional blocks**. **Residual connections** allow the network to **retain** high-resolution **features from the encoder** while progressing **through the decoder**.\n\n\n> * **Finally**, the output part of the model consists of a **Conv2D** layer followed by **Batch Normalization**, **Leaky ReLU** activation, and a final **Conv2D** layer.\n\n\n> * **The learning rate and loss function** hyperparameters were **fine-tuned** through multiple training sessions, **resulting in** the selection of a **learning rate of 0.0003 and mean squared error as the loss function**. While **IoU error and binary cross-entropy are commonly suggested for such projects, mean squared error** was found to yield **better performance in this case**.\n\n\n> * This architecture leverages the U-Net design principles to effectively capture both global and local features while preserving spatial information, thereby enabling accurate segmentation of abnormalities in the brain MRI images.","metadata":{}},{"cell_type":"code","source":"# Convolutional block\ndef conv_block(inputs, n_filters, max_pool=True):\n    x = Conv2D(n_filters, 3, padding='same', kernel_initializer='he_normal', use_bias=False)(inputs)\n    x = BatchNormalization()(x)\n    x = LeakyReLU(0.2)(x)\n    x = Conv2D(n_filters, 3, padding='same', kernel_initializer='he_normal', use_bias=False)(x)\n    x = BatchNormalization()(x)\n    x = LeakyReLU(0.2)(x)\n    skip = x\n    if max_pool:\n        next_layer = MaxPool2D()(x)\n    else:\n        next_layer = x\n    return next_layer, skip\n\n# upsampling block\ndef up_block(reg_inputs, skip_inputs, n_filters):\n    x = Conv2DTranspose(n_filters, 3, 2, padding='same')(reg_inputs)\n    x = concatenate([x, skip_inputs], axis=3)\n    x = conv_block(x, n_filters, max_pool=False)[0]\n    return x\n\n# U-Net model\ndef unet(input_size=(256, 256, 3)):\n    # Encoder block\n    inputs = Input(shape=input_size, name='Input')\n    cb1, cb1_skip = conv_block(inputs, 32)\n    cb2, cb2_skip = conv_block(cb1, 64)\n    cb3, cb3_skip = conv_block(cb2, 128)\n    cb4, cb4_skip = conv_block(cb3, 256)\n    cb5 = conv_block(cb4, 512, max_pool=False)\n    \n    # Decoder block\n    up1 = up_block(cb5[0], cb4_skip, 256)\n    up2 = up_block(up1, cb3_skip, 128)\n    up3 = up_block(up2, cb2_skip, 64)\n    up4 = up_block(up3, cb1_skip, 32)\n    \n    # Output\n    conv1 = Conv2D(32, 3, padding='same', kernel_initializer='he_normal', use_bias=False)(up4)\n    bn = BatchNormalization()(conv1)\n    act = LeakyReLU(0.2)(bn)\n    outputs = Conv2D(1, 1, padding='same', activation='sigmoid', name='Output')(act)\n    \n    # Creating the model\n    unet = Model(inputs=inputs, outputs=outputs)\n    \n    # Compiling the model\n    unet.compile(optimizer=keras.optimizers.Adam(3e-4), loss='mean_squared_error')\n    \n    return unet\n\n# Creating the model\nmodel = unet()\n","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Training**\n> **During training**, the U-Net model **adjusts its weights** to **minimize the discrepancy between the predicted** segmentation masks **and the ground truth** masks.\n\n\n> * **The training process spans 60 epochs**, allowing the model **sufficient time** to iteratively refine its weights. **A small learning rate** facilitates gradual weight updates, **aiding in the convergence towards optimal solutions**.\n\n\n> * Additionally, a **checkpoint callback** is implemented to save the model weights whenever improvements are detected at each epoch, ensuring that the **best-performing** weights are preserved.\n\n\n> * Furthermore, an **early stopping callback** is utilized to halt the training process **if the model fails to demonstrate improvements in weight optimization** after 6 consecutive epochs.\n\n\n> * This strategy helps prevent overfitting and ensures that training concludes efficiently once the model reaches its optimal performance.\n\n\n> * After training, **a plot visualizes** the changes in **training loss and validation loss** across epochs, providing insights into model performance and convergence.","metadata":{}},{"cell_type":"code","source":"# Path to save the best weights\ncheckpoint_path = \"best_model.weights.h5\"\n\n# Defining ModelCheckpoint callback to save the best weights\ncheckpoint_callback = ModelCheckpoint(filepath=checkpoint_path,\n                                      monitor='val_loss',\n                                      save_best_only=True,\n                                      save_weights_only=True,\n                                      verbose=1)\n\n# Defining EarlyStopping callback to prevent overfitting\nearly_stopping = EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True)\n\n# Training the model\nhistory = model.fit(train_dataset, validation_data=validation_dataset,\n                    epochs=EPOCHS, callbacks=[early_stopping, checkpoint_callback])\n\n# Loading the best weights\nmodel.load_weights(\"best_model.weights.h5\")","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **Visualizing model's performance**","metadata":{}},{"cell_type":"code","source":"def plot_history(history):\n    plots = go.Figure([go.Scatter(x=[x+1 for x in range(EPOCHS)], y=history.history['loss'],\n                                  name='Training Loss',mode='lines+markers',\n                                  marker=dict(color='#00008B'),line=dict(width=1),showlegend=True),\n\n                       go.Scatter(x=[x+1 for x in range(EPOCHS)], y=history.history['val_loss'],\n                                  name='Validation Loss',mode='lines+markers',\n                                  marker=dict(color=\"#004EFF\"),line=dict(width=1),showlegend=True)])\n\n    plots.update_layout(\n        title_text=\"Training vs Validation\",\n        title_font=dict(size=25, family='Balto'),\n        title_x=0.5,\n        title_y=0.98,\n        xaxis=dict(title='Epoch', title_font=dict(family='Balto', size=19), tickfont=dict(family='Balto', size=19)),\n        yaxis=dict(title='Loss', title_font=dict(family='Balto', size=19), tickfont=dict(family='Balto', size=19)),\n        margin=dict(l=60, r=20, t=50, b=40),\n        legend=dict(x=0.75, y=0.98, traceorder='normal', orientation='h', font=dict(family='Balto'))  # Placing legend inside\n    )\n\n    plots.show()\n    \nplot_history(history)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### The model is **well-trained** and there is **no sign of over fitting** on train data.","metadata":{}},{"cell_type":"markdown","source":"# **Inferece**\n> Although **Intersection over Union (IoU) is not chosen as a training metric**, **it is utilized during inference** to evaluate predicted masks, showcasing its accuracy in assessing **the similarity between predicted and actual masks**.\n> * **Intersection over Union (IoU):** IoU is a measure of **overlap between two binary masks**, calculated by **dividing the area of overlap by the area of union**, quantifying the extent of agreement between predicted and ground truth masks.\n![0_eTPI-AzczmFh53jz.png](attachment:d3248373-d4bf-41c7-9b20-df995643bd93.png)\n\n\n> * **Prediction:** The **predictions()** function **decodes** images and actual masks from a provided **test dataframe** and **predicts the corresponding masks**. Predicted masks are **thresholded to produce binary values**, with 1 indicating values larger than 0.5 and 0 otherwise. **IoU is computed for each predicted mask**, enabling assessment of segmentation accuracy. Furthermore, **the function performs classification** on input data, distinguishing between negative and positive diagnoses based on predicted masks.\n\n\n> * **Classification:** **As the model also performs classification**, evaluation metrics such as **confusion matrix and classification report** are applied. **Due to the small size of the test dataset, validation data is added to the test dataset for a more comprehensive evaluation**, only under the condition that the average IoU remains stable. The predictions() function is called again, this time on the combined test and validation dataframes, to assess classification metrics.\n\n\n> * **Visualization:** Visualization of 24 positive and 24 negative **images, along with their actual and predicted masks**, offers insights into model performance. **Also, Visualizations for classification part** include plots illustrating **class distribution, confusion matrix, and classification report**, enabling thorough evaluation of model performance.","metadata":{},"attachments":{"d3248373-d4bf-41c7-9b20-df995643bd93.png":{"image/png":"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"}}},{"cell_type":"code","source":"# Calculates IoU\ndef IoU(y_true, y_pred):\n    intersection = tf.reduce_sum(y_true * y_pred, axis=[1,2,3])\n    union = tf.reduce_sum(y_true + y_pred, axis=[1,2,3]) - intersection\n    IoU = (intersection + 1e-25) / (union + 1e-25)  # Adding a small epsilon to avoid division by zero\n    return IoU\n\n# Returns a dataframe containing the IDs, the actual diagnoses, the predicted diagnoses, and IoU for each prediction,\n# along with a dictionary of masks associated with each ID.\ndef predictions(df, threshold=0.5):\n    x = np.array(list(map(lambda v: decode_and_resize_image(v), df['Image'])))\n    y = np.array(list(map(lambda v: decode_and_resize_mask(v), df['Mask'])))\n    \n    # Predicting the masks\n    pred = model.predict(x)\n    \n    # Thresholding predicted mask values\n    pred_thresholded = tf.cast(pred > threshold, dtype=tf.float32)\n    \n    # Getting each mask's IoU\n    IoUs = IoU(y, pred_thresholded).numpy()\n    IoUs = list(map(lambda x: round(x, 3), IoUs))\n    \n    # Takes the largest pixel\n    largest_pixel = lambda y_: np.max(y_)\n    \n    # Determines if the predicted mask contains an abnormality or not (+ or -)\n    # Remember that a negative image's mask is just an entirely black image.\n    diagnotic_function = lambda z: 1 if largest_pixel(z) > 0 else 0\n    \n    # Storing the predicted diagnosis corresponding to each image\n    diagnoses = list(map(lambda x: diagnotic_function(x), pred_thresholded))\n    \n    # Prediction dataframe (Diagnoses and IoUs)\n    prediction_df = pd.DataFrame({'ID': df['ID'].values, 'Actual Diagnosis': df['Diagnosis'].values,\n                                  'Predicted Diagnosis': diagnoses, 'IoU': list(IoUs)})\n    \n    # Prediction dictionary (ID: array of mask values)\n    prediction_dict = {}\n    for i, j in zip(df['ID'].values, pred_thresholded):\n        prediction_dict[i] = j\n    \n    return prediction_dict, prediction_df\n\n# Making predictions\nprediction, prediction_df = predictions(test_df)\n\nprint(len(prediction), list(prediction.values())[0].shape)\n\nprediction_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prediction_df.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### As you can see, **the IoU** scores have an **acceptable mean value**.","metadata":{}},{"cell_type":"code","source":"# IDs for 24 Positive Diagnoses\npositive_ids = list(test_df[test_df['Diagnosis'] == 1]['ID'][:24].values)\n# IDs for 24 Negative Diagnoses\nnegative_ids = list(test_df[test_df['Diagnosis'] == 0]['ID'][:24].values)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Visualization**","metadata":{}},{"cell_type":"markdown","source":"#### **Positive Images and Masks**","metadata":{}},{"cell_type":"code","source":"plot_images_and_masks([test_df.loc[test_df['ID'] == ID, 'Image'].values[0] for ID in positive_ids[:8]],\n                      [test_df.loc[test_df['ID'] == ID, 'Mask'].values[0] for ID in positive_ids[:8]],\n                      [prediction[ID].numpy() for ID in positive_ids[:8]],\n                     [prediction_df.loc[prediction_df['ID'] == ID, 'IoU'].values[0] for ID in positive_ids[:8]])","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_images_and_masks([test_df.loc[test_df['ID'] == ID, 'Image'].values[0] for ID in positive_ids[8:16]],\n                      [test_df.loc[test_df['ID'] == ID, 'Mask'].values[0] for ID in positive_ids[8:16]],\n                      [prediction[ID].numpy() for ID in positive_ids[8:16]],\n                     [prediction_df.loc[prediction_df['ID'] == ID, 'IoU'].values[0] for ID in positive_ids[8:16]])","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_images_and_masks([test_df.loc[test_df['ID'] == ID, 'Image'].values[0] for ID in positive_ids[16:]],\n                      [test_df.loc[test_df['ID'] == ID, 'Mask'].values[0] for ID in positive_ids[16:]],\n                      [prediction[ID].numpy() for ID in positive_ids[16:]],\n                     [prediction_df.loc[prediction_df['ID'] == ID, 'IoU'].values[0] for ID in positive_ids[16:]])","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### **Negative Images and Masks**","metadata":{}},{"cell_type":"code","source":"plot_images_and_masks([test_df.loc[test_df['ID'] == ID, 'Image'].values[0] for ID in negative_ids[:8]],\n                      [test_df.loc[test_df['ID'] == ID, 'Mask'].values[0] for ID in negative_ids[:8]],\n                      [prediction[ID].numpy() for ID in negative_ids[:8]],\n                     [prediction_df.loc[prediction_df['ID'] == ID, 'IoU'].values[0] for ID in negative_ids[:8]])","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_images_and_masks([test_df.loc[test_df['ID'] == ID, 'Image'].values[0] for ID in negative_ids[8:16]],\n                      [test_df.loc[test_df['ID'] == ID, 'Mask'].values[0] for ID in negative_ids[8:16]],\n                      [prediction[ID].numpy() for ID in negative_ids[8:16]],\n                     [prediction_df.loc[prediction_df['ID'] == ID, 'IoU'].values[0] for ID in negative_ids[8:16]])","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_images_and_masks([test_df.loc[test_df['ID'] == ID, 'Image'].values[0] for ID in negative_ids[16:]],\n                      [test_df.loc[test_df['ID'] == ID, 'Mask'].values[0] for ID in negative_ids[16:]],\n                      [prediction[ID].numpy() for ID in negative_ids[16:]],\n                     [prediction_df.loc[prediction_df['ID'] == ID, 'IoU'].values[0] for ID in negative_ids[16:]])","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### The model can **detect negative MRIs accurately**, which makes it **an excellent classifier** too.","metadata":{}},{"cell_type":"markdown","source":"##### As I mentioned earlier, **more data is necessary** to improve the understanding of **classification evaluations**. So, I combine **the validation and test dataframes**.","metadata":{}},{"cell_type":"code","source":"# Making predictions\nprediction, prediction_df = predictions(pd.concat([test_df, val_df], ignore_index=True))\n\nprint(len(prediction), list(prediction.values())[0].shape)\n\nprediction_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prediction_df.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### **Adding validation dataframe** to test dataframe **doesn't affect the IoU mean value significantly**, which means we can use the validation data as unseen data as well (In fact, we can say that the model is not overfitted on the validation dataset).","metadata":{}},{"cell_type":"markdown","source":"### Class Distribution","metadata":{}},{"cell_type":"code","source":"def plot_class_distribution(df):\n    # Counting the actual and predicted class distributions (+, -).\n    class_distribution_df1 = df['Actual Diagnosis'].value_counts()\n    class_distribution_df2 = df['Predicted Diagnosis'].value_counts()\n    mean_IoU = round(df['IoU'].mean(), 3)\n    \n    colors = ['#0504AA', '#ED0101']\n\n    # Defining figure\n    fig = go.Figure()\n\n    # Adding bars for each dataframe and each class\n    for class_label in class_distribution_df1.index:\n        # Getting the name of each class (+ or -)\n        class_name = 'Positive' if class_label == 1 else 'Negative'\n        \n        # Creating stacked bar for each class\n        fig.add_trace(go.Bar(\n            x=['Actual', 'Predicted'],\n            y=[class_distribution_df1.get(class_label, 0),\n               class_distribution_df2.get(class_label, 0)],\n            \n            name=f'{class_name}',\n            marker=dict(color=colors[class_label]),\n            opacity=0.75,\n            width=0.25\n        ))\n    \n    # Updating layout\n    fig.update_layout(\n        height=700,\n        width=800,\n        title_text=f\"Class Distribution | IoU {round(float(mean_IoU), 4)}\",\n        title_font=dict(size=25, family='Balto'),\n        title_x=0.5,\n        title_y=0.98,\n        xaxis=dict(title='Columns', title_font=dict(family='Balto', size=19), tickfont=dict(family='Balto', size=19)),\n        yaxis=dict(title='Count', title_font=dict(family='Balto', size=19), tickfont=dict(family='Balto', size=19)),\n        margin=dict(l=60, r=20, t=50, b=40), \n        legend=dict(x=0.38, y=0.98, traceorder='normal', orientation='h', font=dict(family='Balto')),  # Placing legend inside\n        barmode='stack'  # Setting barmode to 'stack' to stack the bars\n                )\n    # Showing the figure\n    fig.show()\n    \nplot_class_distribution(prediction_df)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Classification metrics","metadata":{}},{"cell_type":"code","source":"# Plots Confusion Matrix\ndef Confusion_Matrix(df):\n    confusionMatrix = confusion_matrix(df['Actual Diagnosis'], df['Predicted Diagnosis'])\n\n    # Defining class names\n    class_names = ['Negative', 'Positive']\n\n    # Normalizing confusion matrix\n    confusionMatrixNormalized = confusionMatrix.astype('float') / confusionMatrix.sum(axis=1)[:, np.newaxis]\n\n    # Creating heatmap trace for confusion matrix\n    heatmap_trace = go.Heatmap(z=confusionMatrixNormalized,\n                               x=class_names,\n                               y=class_names,\n                               colorscale='Viridis',\n                               colorbar=dict(title='Proportion', title_font=dict(family='Balto'),\n                                             tickfont=dict(family='Balto'), tickformat='.2f'))\n\n    # Creating text annotations for each cell in the heatmap\n    annotations = []\n    for i in range(len(class_names)):\n        for j in range(len(class_names)):\n            annotations.append(dict(text=str(confusionMatrix[i, j]),\n                                    x=class_names[j],\n                                    y=class_names[i],\n                                    showarrow=False,\n                                    font=dict(color='black', family='Balto', size=25)))\n\n    # Creating layout\n    layout = go.Layout(height=700,\n                       width=800,\n                       title='Confusion Matrix',\n                       title_font=dict(size=25, family='Balto'),\n                       title_x=0.5,\n                       title_y=0.95,\n                       xaxis=dict(title='Predicted label', title_font=dict(family='Balto', size=19), tickfont=dict(family='Balto', size=19)),\n                       yaxis=dict(title='True label', title_font=dict(family='Balto', size=19), tickfont=dict(family='Balto', size=19)),\n                       annotations=annotations)\n\n    # Creating figure\n    fig = go.Figure(data=[heatmap_trace], layout=layout)\n\n    # Showing the plot\n    fig.show()\n    \nConfusion_Matrix(prediction_df)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Rounds the number of Classification Report output\ndef round_dict(d, decimals=2):\n    if isinstance(d, dict):\n        return {key: round_dict(value, decimals) for key, value in d.items()}\n    else:\n        return round(d, decimals)\n\n# Plots Classification Report\ndef Classification_Report(df):\n    clf_report = classification_report(df['Actual Diagnosis'],\n                                       df['Predicted Diagnosis'],\n                                       labels=np.arange(2),\n                                       target_names=['Negative', 'Positive'],\n                                       output_dict=True)\n\n    rounded_data = round_dict(clf_report, decimals=2)\n\n    # Converting classification report data to dataframe\n    df_clf_report = pd.DataFrame.from_dict(rounded_data)\n\n    # Transposing dataframe for proper visualization\n    df_clf_report = df_clf_report.T\n\n    # Reversing the order of rows in the dataframe\n    df_clf_report = df_clf_report.iloc[::-1]\n\n    # Creating heatmap trace for classification report\n    heatmap_trace = go.Heatmap(z=df_clf_report.values[:, :-1],  # Excluding 'support' column\n                               x=df_clf_report.columns[:-1],  # Excluding 'support' column\n                               y=df_clf_report.index,\n                               colorscale='Viridis')\n\n    # Creating text annotations for each cell in the heatmap\n    annotations = []\n    for i in range(len(df_clf_report.index)):\n        for j in range(len(df_clf_report.columns) - 1):\n            annotations.append(dict(text=str(df_clf_report.values[i, j]),\n                                    x=df_clf_report.columns[j],\n                                    y=df_clf_report.index[i],\n                                    showarrow=False,\n                                    font=dict(color='black', family='Balto', size=22)))\n\n    # Creating layout\n    layout = go.Layout(height=800,\n                       width=800,\n                       title='Classification Report',\n                       title_font=dict(size=25, family='Balto'),\n                       title_x=0.5,\n                       title_y=0.95,\n                       xaxis=dict(title='Metrics', title_font=dict(family='Balto', size=19), tickfont=dict(family='Balto', size=19)),\n                       yaxis=dict(title='Class', title_font=dict(family='Balto', size=19), tickfont=dict(family='Balto', size=19)),\n                       annotations=annotations)\n\n    # Creating figure\n    fig = go.Figure(data=[heatmap_trace], layout=layout)\n\n    # Showing the plot\n    fig.show()\n    \nClassification_Report(prediction_df)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **As we can see, the model can provide both excellent segmentations and accurate classifications.**","metadata":{}}]}